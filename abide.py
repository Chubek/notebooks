# -*- coding: utf-8 -*-
"""ABIDE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XWkMN11pP_2BQtQ7Nr_4-e1mKWeG-6gW
"""

!pip install nilearn
!pip install nibabel

import nilearn.datasets as ds
import pandas as pd
import os
import nibabel as nb
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.preprocessing import LabelBinarizer

from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from keras.optimizers import RMSprop
import plotly.graph_objects as go
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

ds.fetch_abide_pcp(n_subjects=1)

files = os.listdir("/root/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/")
files

file_id = [f.split("_")[1][-5:] for f in files if int(f.split("_")[1][-5:]) > 1]
file_id_2 = [f.split("_")[2][-5:] for f in files if f.split("_")[1][-5:] == "1"]

file_id_main = file_id + file_id_2

len(file_id_main)

pre_data = pd.read_csv("https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv")
pre_data

pre_data_fil = pre_data[pre_data["SUB_ID"].isin(file_id_main)]
pre_data_fil

y = pre_data_fil["DX_GROUP"]

y

file_list = os.listdir("/root/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/")

X = np.zeros((110, 61, 73, 61))

for i, file in zip(range(210), file_list):
    nii_img = nb.load(os.path.join("/root/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/", file))
    
    data = nii_img.get_fdata()
    
    X[i] = data[:, :, :, 0]

X_rs = X.reshape(110, -1)
scaler = StandardScaler()
binarizer = LabelBinarizer()
X_scaled = scaler.fit_transform(X_rs)
X_scaled = X_scaled.reshape(110, 61, 73, 61)
y_binned = binarizer.fit_transform(y.values.reshape(-1, 1))
X_train = X_scaled[:50, :, :, :]
y_train = y_binned[:50]
X_val = X_scaled[50:80, :, :, :]
y_val = y_binned[50:80]
X_test = X_scaled[80:, :, :, :]
y_test = y_binned[80:]

model_conv2d = Sequential()
model_conv2d.add(Conv2D(32, batch_size=10, padding="same", kernel_size=(2,2), 
                        data_format="channels_first",
                        activation="relu", input_shape=(61, 73, 61)))
model_conv2d.add(MaxPooling2D((1, 1)))
model_conv2d.add(Conv2D(64, padding="same", kernel_size=(2,2), 
                        activation="relu"))
model_conv2d.add(MaxPooling2D((1, 1)))
model_conv2d.add(Conv2D(128, padding="same", kernel_size=(2,2),
                        activation="relu"))
model_conv2d.add(MaxPooling2D((1, 1)))
model_conv2d.add(Conv2D(256, padding="same", kernel_size=(2,2),
                        activation="relu"))
model_conv2d.add(MaxPooling2D((1, 1)))
model_conv2d.add(Conv2D(512, padding="same", kernel_size=(2,2), 
                        activation="relu"))
model_conv2d.add(MaxPooling2D((1, 1)))
model_conv2d.add(Flatten())
model_conv2d.add(Dense(512, activation="tanh"))
model_conv2d.add(Dense(1, activation="sigmoid"))

model_conv2d.summary()

model_conv2d.compile(loss="binary_crossentropy", optimizer=RMSprop(lr=1e-8), metrics=["acc"])

model_conv2d.fit(X_train, y_train,
                epochs=30,
                batch_size=10,
                validation_data=(X_val, y_val))

y_pred = model_conv2d.predict(X_test, batch_size=10)

model_conv2d.evaluate(X_test, y_test, batch_size=10)

X_test.shape

!rm -r /root/nilearn_data/

a = [1, 2, 3]
b = [4, 5, 6]

print(list(zip(a, b)))

img = nb.load("/root/nilearn_data/ABIDE_pcp/cpac/nofilt_noglobal/Pitt_0050003_func_preproc.nii.gz")

data = img.get_data()
data.shape

data = data[:, 0:61, :, 0]

x = data[:, 0, 0]
y = data[0, :, 0]
z = data[0, 0, :]

fig = plt.figure()
ax = fig.gca(projection='3d')

ax.plot_trisurf(x, y, z, linewidth=0.2, antialiased=True)

plt.show()

